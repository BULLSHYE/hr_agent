# AI-Powered HR Recruitment Agent

## Project Overview

This project implements an AI-powered HR Recruitment Agent designed to assist HR teams in automating the recruitment workflow. It enables HR professionals to:

- **Upload or Generate Job Descriptions (JD)**: Support for PDF, DOCX, and TXT formats, or AI-generated JDs
- **Discover Candidates**: Fetch candidate data from job portals (currently mocked APIs)
- **Store Candidate Intelligence**: Vector database for semantic search and matching
- **Match Candidates with JDs**: AI-powered similarity scoring and reasoning
- **Generate Personalized Emails**: AI-written emails for candidates and HR notifications
- **Dynamic Model Switching**: Switch between API-based and local LLMs at runtime
- **Docker-Ready**: Fully containerized for easy deployment but not verified due to lack of storage access

The system demonstrates end-to-end AI system design, including AI orchestration, vector memory (RAG), model routing, matching logic, and real-world API simulation.

## ğŸ—ï¸ System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit UI   â”‚â”€â”€â”€â”€â”‚   FastAPI       â”‚
â”‚   Frontend      â”‚    â”‚   Backend       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         â”‚         â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
           â”‚ LangGraph â”‚ â”‚ Vector â”‚ â”‚ Model  â”‚
           â”‚ Workflow  â”‚ â”‚ DB     â”‚ â”‚ Router â”‚
           â”‚           â”‚ â”‚(Chroma)â”‚ â”‚        â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚         â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         â”‚         â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
           â”‚ API LLM   â”‚ â”‚ Local  â”‚ â”‚ Email  â”‚
           â”‚(OpenAI)   â”‚ â”‚ LLM    â”‚ â”‚ Serviceâ”‚
           â”‚           â”‚ â”‚(Ollama)â”‚ â”‚        â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow:

1. HR uploads/generates JD :â¡ï¸ JD is embedded and stored
2. Candidate data fetched and embedded :â¡ï¸ Stored in vector DB
3. Vector DB queried for best candidates :â¡ï¸ Matching scores generated
4. AI generates personalized emails :â¡ï¸ Results displayed in UI

## ğŸ“ Project Structure

```
omni-assignment/
â”œâ”€â”€ docker-compose.yml          # Docker orchestration
â”œâ”€â”€ README.md                   # Project documentation
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ Dockerfile              # Backend container config
â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ ai_flow/                # AI workflow components
â”‚   â”‚   â”œâ”€â”€ graph.py            # LangGraph workflow for recruitment
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                   # Core business logic
â”‚   â”‚   â”œâ”€â”€ chroma_client.py    # ChromaDB vector database client
â”‚   â”‚   â”œâ”€â”€ embeddings.py       # Text embedding utilities
â”‚   â”‚   â”œâ”€â”€ langgraph_workflow.py # JD generation workflow
â”‚   â”‚   â”œâ”€â”€ llm.py              # LLM configuration and routing
â”‚   â”‚   â”œâ”€â”€ logging.py          # Logging middleware
â”‚   â”‚
â”‚   â”œâ”€â”€ db/                     # Database layer
â”‚   â”‚   â”œâ”€â”€ db.py               # SQLAlchemy database setup
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # Data models
â”‚   â”‚   â”œâ”€â”€ job_descriptions.py # JD model
â”‚   â”‚   â”œâ”€â”€ user.py             # User model
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/                 # API endpoints
â”‚   â”‚   â”œâ”€â”€ candidates.py       # Candidate management
â”‚   â”‚   â”œâ”€â”€ choose_model.py     # Model selection
â”‚   â”‚   â”œâ”€â”€ email.py            # Email generation
â”‚   â”‚   â”œâ”€â”€ job_descriptions.py # JD operations
â”‚   â”‚   â”œâ”€â”€ match_score.py      # Matching logic
â”‚   â”‚   â”œâ”€â”€ user.py             # Authentication
â”‚   â”‚
â”‚   â”œâ”€â”€ schema/                 # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ candidates.py       # Candidate schemas
â”‚   â”‚   â”œâ”€â”€ choose_model.py     # Model schemas
â”‚   â”‚   â”œâ”€â”€ email.py            # Email schemas
â”‚   â”‚   â”œâ”€â”€ job_descriptions.py # JD schemas
â”‚   â”‚   â”œâ”€â”€ match_score.py      # Match schemas
â”‚   â”‚   â”œâ”€â”€ user.py             # User schemas
â”‚   â”‚
â”‚   â”œâ”€â”€ services/               # Business services
â”‚   â”‚   â”œâ”€â”€ candidates.py       # Candidate services
â”‚   â”‚   â”œâ”€â”€ email.py            # Email services
â”‚   â”‚   â”œâ”€â”€ job_descriptions.py # JD services
â”‚   â”‚   â”œâ”€â”€ match_score.py      # Matching services
â”‚   â”‚
â”‚   â””â”€â”€ utilities/              # Utility functions
â”‚       â”œâ”€â”€ auth.py             # Authentication utilities
â”‚       â”œâ”€â”€ crypt.py            # Encryption utilities
â”‚       â”œâ”€â”€ jd_parser.py        # JD parsing utilities
â”‚       â”œâ”€â”€ mock_sources.py     # Mock data sources
â”‚
â”œâ”€â”€ frontend/                   # Streamlit frontend
â”‚   â”œâ”€â”€ Dockerfile              # Frontend container config
â”‚   â”œâ”€â”€ app.py                  # Streamlit application
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚
â””â”€â”€ chroma_db/                 # ChromaDB persistent storage
    â”œâ”€â”€ chroma.sqlite3
    â””â”€â”€ [collection_dirs]/
```

## ğŸ§  Why LangGraph / LangChain

### LangGraph Selection:

LangGraph is chosen for AI orchestration because it provides:

- **State-based Workflows**: Maintains shared state across all steps (job details, candidate data, scores, decisions), simplifying data flow
- **Complex Reasoning Pipelines**: Ideal for structured flows such as: Job Description â†’ Candidate Profile â†’ Matching Logic â†’ Decision â†’ Email Generation
  This is more reliable than running independent LangChain calls.
- **Built-in Features**:
  - Model switching capabilities
  - Tool calling integration
  - Reasoning traceability and debugging
  - Conditional branching and loops

### LangChain Integration:

LangChain components are used for:

- **LLM Abstraction**: making the system flexible and future-proof and working with different LLM providers (OpenAI, Anthropic, local models)
- **Prompt Engineering**: Structured prompt templates and chains and AI response handling
- **Tool Integration**: Connecting LLMs with external tools and APIs
- **Memory Management**: Conversation history and context retention with individual steps

### Workflow Benefits:

- **Recruitment Pipeline**: Structured flow from JD processing to email generation
- **Error Handling**: Built-in retry mechanisms and fallback strategies
- **Observability**: Graph visualization and execution tracing
- **Scalability**: Easy to extend with new nodes and edges

## ğŸ—ƒï¸ Why Selected Vector DB (ChromaDB)

ChromaDB was selected as the vector database because:

### Technical Advantages:

- **Lightweight & Local-First**: No cloud dependency, runs locally
- **Metadata Filtering**: Supports complex queries with metadata
- **Easy Integration**: Python-native with simple API and for testing and development
- **Performance**: Fast similarity search with HNSW indexing

### Project-Specific Benefits:

- **Candidate Memory**: Efficient storage and retrieval of candidate profiles
- **JD Storage**: Semantic search across job descriptions
- **RAG Workflows**: Perfect for retrieval-augmented generation
- **Development Friendly**: Easy setup for local development and testing

### Alternatives Considered:

- **Pinecone**: Cloud-only, requires API keys and internet and free some limitations
- **Weaviate**: More complex setup and configuration and Pay-as-you-go pricing model
- **FAISS**: Lacks metadata filtering and persistence and
- **ChromaDB**: Best fit for local, lightweight vector operations

## ğŸ¤– Model Selection Strategy

The system implements a hybrid model approach supporting two modes:

### API-based Models (Primary):

- **OpenAI GPT Models** (GPT-4o-mini, GPT-4)
- **Use Cases**:
  - Job description generation
  - Candidate matching explanations
  - Personalized email generation
  - Complex reasoning tasks

### Local Models (Fallback):

- **Phi-3 / Mistral** via Ollama
- **Use Cases**:
  - Offline operation
  - Backup when API unavailable
  - Cost-sensitive scenarios
  - Privacy requirements

### Dynamic Switching:

- **Runtime Selection**: Switch models via `POST /model/select` endpoint
- **Configuration**: Environment-based model selection
- **Fallback Logic**: Automatic switch to local models on API failure

## âš–ï¸ Local vs API Model Trade-offs

| Aspect          | API Models              | Local Models                 |
| --------------- | ----------------------- | ---------------------------- |
| **Quality**     | Higher quality outputs  | Good but variable quality    |
| **Setup**       | Faster (API key only)   | Requires Ollama installation |
| **Cost**        | Paid per token          | Free (one-time setup)        |
| **Speed**       | Faster inference        | Slower on consumer hardware  |
| **Privacy**     | Data sent to providers  | Fully local, private         |
| **Reliability** | Dependent on internet   | Always available offline     |
| **Resources**   | Minimal local resources | Requires GPU/CPU resources   |

### Strategy:

- **Default**: API models for quality and speed
- **Fallback**: Local models for resilience and privacy
- **Hybrid**: Runtime switching based on requirements

## ğŸ”Œ API Endpoints as per the documents

| Method | Endpoint             | Description                   |
| ------ | -------------------- | ----------------------------- |
| `GET`  | `/`                  | Health check with timestamp   |
| `POST` | `/auth/login`        | User authentication           |
| `POST` | `/auth/register`     | User registration             |
| `POST` | `/jd/upload`         | Upload JD (PDF, DOCX, TXT)    |
| `POST` | `/jd/generate`       | Generate JD using AI          |
| `GET`  | `/jd/list`           | List all job descriptions     |
| `POST` | `/model/select`      | Select LLM (API/Local)        |
| `POST` | `/candidates/fetch`  | Fetch candidates from sources |
| `POST` | `/candidates/store`  | Store candidate embeddings    |
| `GET`  | `/candidates/search` | Semantic candidate search     |
| `POST` | `/match/score`       | JD-candidate matching         |
| `POST` | `/email/send`        | Generate & send emails        |

### API Documentation:

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`
- **OpenAPI JSON**: `http://localhost:8000/openapi.json`

## â–¶ï¸ How to Run Locally (Without Docker)

### Prerequisites:

- Python 3.10+
- Ollama (for local models)
- OpenAI API key

### Backend Setup:

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Frontend Setup:

```bash
cd frontend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
streamlit run app.py --server.port=8501 --server.address=0.0.0.0
```

### Environment Variables:

Create `.env` file in backend directory:

```env
openai_api_key=your_openai_key
gemini_api_key=your_gemini_key
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your_email@gmail.com
SMTP_PASSWORD=your_app_password
DATABASE_URL=sqlite:///./hr_agent.db
SECRET_KEY=your_secret_key
```

## ğŸ³ Docker Setup

### Prerequisites:

- Docker & Docker Compose
- `.env` file with required variables

### Quick Start:

```bash
# Clone repository
git clone <repository-url>
cd omni-assignment

# Create environment file
cp .env.example .env
# Edit .env with your API keys

# Build and run
docker-compose up --build
```

### Access Points:

| Service        | URL                          | Description             |
| -------------- | ---------------------------- | ----------------------- |
| Backend API    | `http://localhost:8000/docs` | FastAPI Swagger UI      |
| Frontend UI    | `http://localhost:8501`      | Streamlit Web Interface |
| Backend Health | `http://localhost:8000/`     | Health check endpoint   |

### Docker Commands:

```bash
# Build only
docker-compose build

# Run in background
docker-compose up -d

# View logs
docker-compose logs -f backend
docker-compose logs -f frontend

# Stop services
docker-compose down

# Rebuild after changes
docker-compose up --build --force-recreate
```

## âš ï¸ Assumptions & Limitations

### Assumptions:

- **Mock Data Sources**: Candidate APIs are simulated (LinkedIn, Naukri, etc.)
- **Single User**: Designed for individual HR user workflows
- **English Language**: All processing assumes English content
- **Limited Concurrency**: Not optimized for high concurrent users
- **Local Vector DB**: ChromaDB runs locally with file-based persistence

### Limitations:

- **No Authentication UI**: API-only authentication (no login forms)
- **Mock Integrations**: No real job portal API connections
- **No Persistent Relational DB**: Only vector database, no user/session persistence
- **Basic UI**: Not production-grade UI/UX
- **Single JD Processing**: Processes one JD at a time
- **Email Dependencies**: Requires SMTP configuration for email features
- **Resource Intensive**: Local LLM requires significant hardware resources

## ğŸš€ Future Improvements

- **Real API Integrations**: LinkedIn, Naukri, Indeed API connections
- **User Authentication UI**: Login/register forms
- **Resume Upload & Parsing**: PDF/DOCX resume processing
- **Multi-JD Support**: Batch processing multiple job descriptions
- **Database Migration**: PostgreSQL/MySQL for relational data

- **Feedback Loop**: User feedback for improving match scores
- **Streaming Responses**: Real-time LLM response streaming properly
- **Background Jobs**: Celery/Redis for async processing
- **Advanced Matching**: Skills gap analysis, culture fit scoring

- **Observability**: Comprehensive logging, metrics, tracing
- **Dashboard UI**: Analytics dashboard with charts and KPIs
- **Multi-Language Support**: Support for non-English content
- **Cloud Deployment**: AWS/GCP/Azure deployment configurations
- **Mobile App**: React Native mobile companion app
- **AI Model Fine-tuning**: Custom model training on recruitment data

## ğŸ“¦ Tech Stack

### Backend:

- **Framework**: FastAPI
- **AI Orchestration**: LangGraph + LangChain
- **Vector Database**: ChromaDB
- **LLM Providers**: OpenAI, Gemini, Ollama (local)
- **Database**: SQLAlchemy + SQLite
- **Authentication**: JWT tokens
- **Email**: SMTP integration

### Frontend:

- **Framework**: Streamlit
- **HTTP Client**: Requests library
- **UI Components**: Streamlit native components

### Infrastructure:

- **Containerization**: Docker + Docker Compose
- **Process Management**: Uvicorn (backend), Streamlit (frontend)
- **Environment**: Python 3.10+
- **Dependencies**: Poetry/pip for package management

### Development Tools:

- **Documentation**: Swagger/ReDoc auto-generated
- **Version Control**: Git

## ğŸ Conclusion

This AI-powered HR Recruitment Agent demonstrates:

- âœ… **End-to-end AI System Design**: Complete pipeline from JD to email
- âœ… **AI Orchestration**: LangGraph for complex workflows
- âœ… **Vector Memory**: ChromaDB for semantic search and RAG
- âœ… **Matching Logic**: Cosine similarity with AI-powered reasoning
- âœ… **Model Flexibility**: Dynamic switching between API and local LLMs
- âœ… **Production Readiness**: Docker containerization and API design
- âœ… **Scalable Architecture**: Modular design for easy extension
